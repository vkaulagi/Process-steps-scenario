{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2db67ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Any\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "nltk.download('universal_tagset')\n",
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb752e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = json.load(open(r\"D:\\Any\\Desktop\\Research\\tags.json\", \"r\"))\n",
    "sampled_tags1 = json.load(open(r\"D:\\Any\\Desktop\\Research\\sampled_tags1.json\", \"r\"))\n",
    "sampled_tags2 = json.load(open(r\"D:\\Any\\Desktop\\Research\\sampled_tags2.json\", \"r\"))\n",
    "sampled_tags3 = json.load(open(r\"D:\\Any\\Desktop\\Research\\sampled_tags3.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24f1bb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf756abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in sampled_tags1:\n",
    "    tags.remove(x)\n",
    "\n",
    "for x in sampled_tags2:\n",
    "    if x in tags:\n",
    "        tags.remove(x)\n",
    "        \n",
    "for x in sampled_tags3:\n",
    "    if x in tags:\n",
    "        tags.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee959448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0a1fed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tags(df):\n",
    "    sentences = [s for para in df['text'] for s in nltk.sent_tokenize(para)]\n",
    "    tokenized_text = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "    tags = [nltk.pos_tag(word, tagset='universal') for word in tokenized_text]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e1985167",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios2 = pd.read_json(\"D:\\Any\\Desktop\\Research\\scenarios2.json\")\n",
    "tags2 = create_tags(scenarios2)\n",
    "scenarios3 = pd.read_json(\"D:\\Any\\Desktop\\Research\\scenarios3.json\")\n",
    "tags3 = create_tags(scenarios3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db291e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(tags):\n",
    "    sampled_tags_vk = random.sample(tags, int(len(tags)/2))\n",
    "    sampled_tags_tb = []\n",
    "    for x in tags:\n",
    "        if x not in sampled_tags_vk:\n",
    "            sampled_tags_tb.append(x)\n",
    "    return sampled_tags_vk, sampled_tags_tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "79e44f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_sampled_tags_scenarios1_vk, remaining_sampled_tags_scenarios1_tb = create_samples(tags)\n",
    "with open('remaining_sampled_tags_scenarios1_vk.json', 'w') as f:\n",
    "    json.dump(remaining_sampled_tags_scenarios1_vk, f)\n",
    "with open('remaining_sampled_tags_scenarios1_tb.json', 'w') as f:\n",
    "    json.dump(remaining_sampled_tags_scenarios1_tb, f)\n",
    "\n",
    "sampled_tags_scenarios2_vk, sampled_tags_scenarios2_tb = create_samples(tags2)\n",
    "with open('sampled_tags_scenarios2_vk.json', 'w') as f:\n",
    "    json.dump(sampled_tags_scenarios2_vk, f)\n",
    "with open('sampled_tags_scenarios2_tb.json', 'w') as f:\n",
    "    json.dump(sampled_tags_scenarios2_tb, f)\n",
    "\n",
    "sampled_tags_scenarios3_vk, sampled_tags_scenarios3_tb = create_samples(tags3)\n",
    "with open('sampled_tags_scenarios3_vk.json', 'w') as f:\n",
    "    json.dump(sampled_tags_scenarios3_vk, f)\n",
    "with open('sampled_tags_scenarios3_tb.json', 'w') as f:\n",
    "    json.dump(sampled_tags_scenarios3_tb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "802df6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remaining_sampled_tags_scenarios1_vk) + len(sampled_tags_scenarios2_vk) + len(sampled_tags_scenarios3_vk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66e2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
